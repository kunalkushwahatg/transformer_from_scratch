{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b8aca8fa-191d-4294-b199-b7fda4d55b3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8aca8fa-191d-4294-b199-b7fda4d55b3d",
        "outputId": "de9d31ea-2383-4399-929e-e836b7f60d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import string\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import math\n",
        "import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Current device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "62d6fd62-61cb-4740-a727-d48ee65f4abd",
      "metadata": {
        "id": "62d6fd62-61cb-4740-a727-d48ee65f4abd"
      },
      "outputs": [],
      "source": [
        "file = open(\"input.txt\",\"r\",encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text = text.replace(\"\\n\" , \" \").lower()\n",
        "punctuation_chars = string.punctuation\n",
        "text = ''.join(char for char in text if char not in punctuation_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f9fe132d-ad12-4ddc-b57c-2e507029f5d9",
      "metadata": {
        "id": "f9fe132d-ad12-4ddc-b57c-2e507029f5d9"
      },
      "outputs": [],
      "source": [
        "tokens = text.split(\" \")\n",
        "vocab = list(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b6f2ad48-ea79-4da8-aac3-fba00fc620a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6f2ad48-ea79-4da8-aac3-fba00fc620a0",
        "outputId": "222d024b-930a-430b-8437-861788f9347c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12849/12849 [00:58<00:00, 220.01it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm.tqdm(vocab):\n",
        "    if tokens.count(i) < 5:\n",
        "        tokens.remove(i)\n",
        "vocab = list(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "278f74d0-ba94-4893-90c7-1268dbb953d0",
      "metadata": {
        "id": "278f74d0-ba94-4893-90c7-1268dbb953d0"
      },
      "outputs": [],
      "source": [
        "vocab_to_idx = {}\n",
        "idx_to_vocab = {}\n",
        "vocab_size = len(vocab)\n",
        "for idx,v in enumerate(vocab):\n",
        "    vocab_to_idx[v] = idx\n",
        "    idx_to_vocab[idx] = v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "697f756a-e3e4-49a8-8e84-7771e991898e",
      "metadata": {
        "id": "697f756a-e3e4-49a8-8e84-7771e991898e"
      },
      "outputs": [],
      "source": [
        "tokens_num = []\n",
        "for i in tokens:\n",
        "    tokens_num.append(vocab_to_idx[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3372603f-19b1-4fa5-9a96-b1b82fc47500",
      "metadata": {
        "id": "3372603f-19b1-4fa5-9a96-b1b82fc47500"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "x_num = []\n",
        "y_num = []\n",
        "max_len = 10\n",
        "for i in range(len(tokens) - max_len - 1):\n",
        "    x.append(tokens[i:max_len+i])\n",
        "    y.append(tokens[max_len+i])\n",
        "    x_num.append(tokens_num[i:max_len+i])\n",
        "    y_num.append(tokens_num[max_len+i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dfa428b1-b826-42ff-96ec-3e8fe3ee9c91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfa428b1-b826-42ff-96ec-3e8fe3ee9c91",
        "outputId": "d9c61d3a-6e82-4ae7-c5a0-109007f343c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak']\n",
            "\n",
            "['citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '']\n",
            "all\n",
            "['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all']\n",
            "speak\n",
            "['we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak']\n",
            "speak\n",
            "['proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak']\n",
            "\n",
            "['any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak', '']\n",
            "first\n",
            "['further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak', '', 'first']\n",
            "citizen\n",
            "['hear', 'me', 'speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen']\n",
            "you\n",
            "['me', 'speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen', 'you']\n",
            "are\n",
            "['speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen', 'you', 'are']\n",
            "all\n",
            "[3949, 6506, 2275, 1298, 5625, 2177, 4241, 2515, 6106, 2949]\n",
            "0\n",
            "[6506, 2275, 1298, 5625, 2177, 4241, 2515, 6106, 2949, 0]\n",
            "2190\n",
            "[2275, 1298, 5625, 2177, 4241, 2515, 6106, 2949, 0, 2190]\n",
            "2949\n",
            "[1298, 5625, 2177, 4241, 2515, 6106, 2949, 0, 2190, 2949]\n",
            "2949\n",
            "[5625, 2177, 4241, 2515, 6106, 2949, 0, 2190, 2949, 2949]\n",
            "0\n",
            "[2177, 4241, 2515, 6106, 2949, 0, 2190, 2949, 2949, 0]\n",
            "3949\n",
            "[4241, 2515, 6106, 2949, 0, 2190, 2949, 2949, 0, 3949]\n",
            "6506\n",
            "[2515, 6106, 2949, 0, 2190, 2949, 2949, 0, 3949, 6506]\n",
            "3072\n",
            "[6106, 2949, 0, 2190, 2949, 2949, 0, 3949, 6506, 3072]\n",
            "1507\n",
            "[2949, 0, 2190, 2949, 2949, 0, 3949, 6506, 3072, 1507]\n",
            "2190\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(x[i])\n",
        "    print(y[i])\n",
        "for i in range(10):\n",
        "    print(x_num[i])\n",
        "    print(y_num[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6e5821fc-f26d-43d3-ad1c-396410330255",
      "metadata": {
        "id": "6e5821fc-f26d-43d3-ad1c-396410330255"
      },
      "outputs": [],
      "source": [
        "dmodel = 512\n",
        "heads = 4\n",
        "batch_size = 32\n",
        "max_len = 10\n",
        "shape = (batch_size,max_len,dmodel)\n",
        "sentence = torch.Tensor(x_num).long()\n",
        "label = torch.Tensor(y_num).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "642e7702-4c53-4978-a74d-09f50c65802f",
      "metadata": {
        "id": "642e7702-4c53-4978-a74d-09f50c65802f"
      },
      "outputs": [],
      "source": [
        "batch = []\n",
        "for i in range(sentence.shape[0]//32):\n",
        "    if i == 0:\n",
        "        batch.append([sentence[0:32],label[0:32]])\n",
        "    else:\n",
        "        batch.append([sentence[i*32:(i+1)*32],label[i*32:(i+1)*32]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2e3f3c3b-2c07-4e01-b76c-25153e5a7143",
      "metadata": {
        "id": "2e3f3c3b-2c07-4e01-b76c-25153e5a7143"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    '''\n",
        "    Converts the vector embedding of a batch of sequences to their positional encoding vectors.\n",
        "\n",
        "    Arguments:\n",
        "            shape : shape of embedding vector => tuple(batch_size, max_len, dmodel)\n",
        "            device : device to perform the computation on (e.g., 'cpu' or 'cuda')\n",
        "\n",
        "    Returns:\n",
        "            positional encoded vector\n",
        "\n",
        "    '''\n",
        "    def __init__(self, shape, device='cpu'):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.max_len = shape[1]\n",
        "        self.dmodel = shape[2]\n",
        "        self.device = device\n",
        "\n",
        "        position = torch.arange(0, self.max_len, device=self.device).float().unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, self.dmodel, 2, device=self.device).float() * -(math.log(10000.0) / self.dmodel))\n",
        "\n",
        "        pos_enc = torch.zeros((1, self.max_len, self.dmodel), device=self.device)\n",
        "        pos_enc[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pos_enc[0, :, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.pos_enc = pos_enc\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pos_enc[:, :x.size(1), :]\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2738ce16-3467-4300-b3bb-92442eadaca1",
      "metadata": {
        "id": "2738ce16-3467-4300-b3bb-92442eadaca1"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    '''\n",
        "    Multi-Head Attention mechanism for transformer models.\n",
        "\n",
        "    Arguments:\n",
        "        dmodel: Dimension of the model\n",
        "        heads: Number of attention heads\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Perform multi-head attention on the input tensor x\n",
        "    '''\n",
        "    def __init__(self, dmodel, heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.dmodel = dmodel\n",
        "        self.heads = heads\n",
        "        self.head_size = dmodel // heads\n",
        "\n",
        "        self.k_linear = nn.Linear(dmodel, dmodel)\n",
        "        self.q_linear = nn.Linear(dmodel, dmodel)\n",
        "        self.v_linear = nn.Linear(dmodel, dmodel)\n",
        "        self.out_linear = nn.Linear(dmodel, dmodel)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        '''\n",
        "        Split the last dimension into (heads, head_size) and transpose to shape (batch_size, heads, seq_len, head_size).\n",
        "        '''\n",
        "        return x.view(batch_size, -1, self.heads, self.head_size).transpose(1, 2)\n",
        "\n",
        "    def attention(self, k, q, v):\n",
        "        '''\n",
        "        Compute the attention weights and apply them to the value vectors.\n",
        "        '''\n",
        "        d_k = q.size(-1)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32, device=q.device))\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        return torch.matmul(attn, v)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Perform the multi-head attention mechanism on the input tensor x.\n",
        "        '''\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        K = self.split_heads(self.k_linear(x), batch_size)  # Key: What can I offer\n",
        "        Q = self.split_heads(self.q_linear(x), batch_size)  # Query: What am I looking for\n",
        "        V = self.split_heads(self.v_linear(x), batch_size)  # Value: What I actually offer\n",
        "\n",
        "        attn_output = self.attention(K, Q, V)\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.dmodel)\n",
        "\n",
        "        return self.out_linear(attn_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fd3a1554-fac1-45a2-a86a-9d817e7b0eb3",
      "metadata": {
        "id": "fd3a1554-fac1-45a2-a86a-9d817e7b0eb3"
      },
      "outputs": [],
      "source": [
        "class AddAndNorm(nn.Module):\n",
        "    '''\n",
        "    Add and Layer Normalization module for transformer models.\n",
        "\n",
        "    Arguments:\n",
        "        dmodel: Dimension of the model\n",
        "\n",
        "    Methods:\n",
        "        forward(x, residual): Add the input tensor x and the residual tensor, then apply layer normalization\n",
        "    '''\n",
        "    def __init__(self, dmodel):\n",
        "        super(AddAndNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(dmodel)\n",
        "\n",
        "    def forward(self, x, residual):\n",
        "        '''\n",
        "        Add the input tensor x and the residual tensor, then apply layer normalization.\n",
        "\n",
        "        Arguments:\n",
        "            x: Input tensor\n",
        "            residual: Residual tensor to be added to the input tensor\n",
        "\n",
        "        Returns:\n",
        "            Tensor after addition and layer normalization\n",
        "        '''\n",
        "        return self.layer_norm(x + residual)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3abf7b27-898e-4eca-a720-1da2abea3419",
      "metadata": {
        "id": "3abf7b27-898e-4eca-a720-1da2abea3419"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    '''\n",
        "    Position-wise Feed-Forward Network for transformer models with dropout.\n",
        "\n",
        "    Arguments:\n",
        "        dmodel: Dimension of the model\n",
        "        dropout: Dropout probability\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Apply the feed-forward network with dropout on the input tensor x\n",
        "    '''\n",
        "    def __init__(self, dmodel, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(dmodel, dmodel)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dmodel, dmodel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Apply the feed-forward network with dropout on the input tensor x.\n",
        "\n",
        "        Arguments:\n",
        "            x: Input tensor\n",
        "\n",
        "        Returns:\n",
        "            Tensor after applying the feed-forward network and dropout\n",
        "        '''\n",
        "        return self.linear2(self.dropout(self.relu(self.linear1(x))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "a997cda3-7168-4fe7-994a-48fb53bd0ed6",
      "metadata": {
        "id": "a997cda3-7168-4fe7-994a-48fb53bd0ed6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    Transformer Encoder implementation.\n",
        "\n",
        "    Arguments:\n",
        "        vocab_size: Size of the vocabulary\n",
        "        shape: Shape of the input tensor (batch_size, max_len, dmodel)\n",
        "        heads: Number of attention heads\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Forward pass through the encoder\n",
        "    '''\n",
        "    def __init__(self, vocab_size, shape, heads=4):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, shape[2])\n",
        "        self.positional_encoding = PositionalEncoding(shape,device=device)\n",
        "        self.multi_headed_attention = MultiHeadAttention(shape[2], heads)\n",
        "        self.add_and_norm1 = AddAndNorm(shape[2])\n",
        "        self.feed_forward = FeedForward(dmodel=shape[2])\n",
        "        self.add_and_norm2 = AddAndNorm(shape[2])\n",
        "        self.linear = nn.Linear(shape[2], 512)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.token_embedding_table(x)\n",
        "        residual = self.positional_encoding(out)\n",
        "        out = self.multi_headed_attention(residual)\n",
        "\n",
        "        residual = self.add_and_norm1(out, residual)\n",
        "\n",
        "        out = self.feed_forward(residual)\n",
        "        out = self.add_and_norm2(out, residual)\n",
        "\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "1fed33ce",
      "metadata": {
        "id": "1fed33ce"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Pretraining(nn.Module):\n",
        "    '''\n",
        "    Pretraining model for next word prediction using a transformer encoder.\n",
        "\n",
        "    Arguments:\n",
        "        vocab_size: Size of the vocabulary\n",
        "        shape: Shape of the input tensor (batch_size, max_len, dmodel)\n",
        "        heads: Number of attention heads\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Forward pass through the pretraining model\n",
        "        predict_next_word(x): Predict the next word for the input sequence\n",
        "    '''\n",
        "    def __init__(self, vocab_size, shape, heads=4):\n",
        "        super(Pretraining, self).__init__()\n",
        "        self.encoder = Encoder(vocab_size, shape, heads)\n",
        "        self.linear = nn.Linear(shape[2] * shape[1], vocab_size)\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = out.view(out.size(0), -1) #torch.Size([Batch,time*dmodel])\n",
        "        out = self.linear(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "5b97bbdd-127d-495e-b32c-ab099312f78b",
      "metadata": {
        "id": "5b97bbdd-127d-495e-b32c-ab099312f78b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddd68de-957c-4945-f91f-874c1792a6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:49<00:00, 57.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 6.145278875735225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:49<00:00, 57.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 5.546202123688897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:49<00:00, 57.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Average Loss: 4.801016961448317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:49<00:00, 57.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Average Loss: 4.067565264879352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:49<00:00, 57.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Average Loss: 3.4987538750321363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:48<00:00, 57.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Average Loss: 3.064599224145581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:48<00:00, 57.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Average Loss: 2.7542555458840137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:48<00:00, 57.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Average Loss: 2.508637972791501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:49<00:00, 57.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Average Loss: 2.2968764330826925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6259/6259 [01:48<00:00, 57.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Average Loss: 2.127277320919564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Pretraining(vocab_size,shape)\n",
        "criterition = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "import random\n",
        "random.shuffle(batch)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    losses = []\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for b in tqdm.tqdm(batch):\n",
        "        inputs, targets = b[0].to(device), b[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        res = model(inputs)\n",
        "        loss  = criterition(res ,targets)\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "    # Calculate and print the average loss for the epoch\n",
        "    average_loss = running_loss / len(batch)\n",
        "    print(f'Epoch {epoch + 1}, Average Loss: {average_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "id": "b8c69d0b",
      "metadata": {
        "id": "b8c69d0b"
      },
      "outputs": [],
      "source": [
        "#softmax res\n",
        "res = nn.Softmax(dim=-1)(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "Fml8-Hy9s_Jj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fml8-Hy9s_Jj",
        "outputId": "cf4a659e-9131-4d29-e88e-9b18727e45b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it\n"
          ]
        }
      ],
      "source": [
        "sentence = 'we welcome to the book of writing making working can'\n",
        "tokens = sentence.split(\" \")\n",
        "tokens_num = []\n",
        "for i in tokens:\n",
        "    tokens_num.append(vocab_to_idx[i])\n",
        "\n",
        "out = model(torch.tensor(tokens_num).unsqueeze(0).to(device))\n",
        "out = nn.Softmax(dim=-1)(out)\n",
        "out = torch.argmax(out,dim=-1).item()\n",
        "print(idx_to_vocab[out])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgr8j9d64fEJ"
      },
      "id": "qgr8j9d64fEJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}