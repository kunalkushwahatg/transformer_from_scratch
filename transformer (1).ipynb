{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b8aca8fa-191d-4294-b199-b7fda4d55b3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8aca8fa-191d-4294-b199-b7fda4d55b3d",
        "outputId": "37e74ffc-1be5-45eb-b59d-38eb22123950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import string\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import math\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Current device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "62d6fd62-61cb-4740-a727-d48ee65f4abd",
      "metadata": {
        "id": "62d6fd62-61cb-4740-a727-d48ee65f4abd"
      },
      "outputs": [],
      "source": [
        "file = open(\"/content/tiny-shakespeare.txt\",\"r\",encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text = text.replace(\"\\n\" , \" \").lower()\n",
        "punctuation_chars = string.punctuation\n",
        "text = ''.join(char for char in text if char not in punctuation_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f9fe132d-ad12-4ddc-b57c-2e507029f5d9",
      "metadata": {
        "id": "f9fe132d-ad12-4ddc-b57c-2e507029f5d9"
      },
      "outputs": [],
      "source": [
        "tokens = text.split(\" \")\n",
        "vocab = list(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b6f2ad48-ea79-4da8-aac3-fba00fc620a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6f2ad48-ea79-4da8-aac3-fba00fc620a0",
        "outputId": "db30a856-c004-49f7-a616-ba4de0c1f9e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12849/12849 [00:57<00:00, 223.69it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm.tqdm(vocab):\n",
        "    if tokens.count(i) < 5:\n",
        "        tokens.remove(i)\n",
        "vocab = list(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "278f74d0-ba94-4893-90c7-1268dbb953d0",
      "metadata": {
        "id": "278f74d0-ba94-4893-90c7-1268dbb953d0"
      },
      "outputs": [],
      "source": [
        "vocab_to_idx = {}\n",
        "idx_to_vocab = {}\n",
        "vocab_size = len(vocab)\n",
        "for idx,v in enumerate(vocab):\n",
        "    vocab_to_idx[v] = idx\n",
        "    idx_to_vocab[idx] = v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "697f756a-e3e4-49a8-8e84-7771e991898e",
      "metadata": {
        "id": "697f756a-e3e4-49a8-8e84-7771e991898e"
      },
      "outputs": [],
      "source": [
        "tokens_num = []\n",
        "for i in tokens:\n",
        "    tokens_num.append(vocab_to_idx[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3372603f-19b1-4fa5-9a96-b1b82fc47500",
      "metadata": {
        "id": "3372603f-19b1-4fa5-9a96-b1b82fc47500"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "x_num = []\n",
        "y_num = []\n",
        "max_len = 10\n",
        "for i in range(len(tokens) - max_len - 1):\n",
        "    x.append(tokens[i:max_len+i])\n",
        "    y.append(tokens[max_len+i])\n",
        "    x_num.append(tokens_num[i:max_len+i])\n",
        "    y_num.append(tokens_num[max_len+i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dfa428b1-b826-42ff-96ec-3e8fe3ee9c91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfa428b1-b826-42ff-96ec-3e8fe3ee9c91",
        "outputId": "8f58d31e-b61a-4b15-a1fa-f1837c02d49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak']\n",
            "\n",
            "['citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '']\n",
            "all\n",
            "['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all']\n",
            "speak\n",
            "['we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak']\n",
            "speak\n",
            "['proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak']\n",
            "\n",
            "['any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak', '']\n",
            "first\n",
            "['further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak', '', 'first']\n",
            "citizen\n",
            "['hear', 'me', 'speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen']\n",
            "you\n",
            "['me', 'speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen', 'you']\n",
            "are\n",
            "['speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen', 'you', 'are']\n",
            "all\n",
            "[5632, 3263, 3904, 2364, 972, 2094, 5173, 5004, 4088, 6176]\n",
            "0\n",
            "[3263, 3904, 2364, 972, 2094, 5173, 5004, 4088, 6176, 0]\n",
            "383\n",
            "[3904, 2364, 972, 2094, 5173, 5004, 4088, 6176, 0, 383]\n",
            "6176\n",
            "[2364, 972, 2094, 5173, 5004, 4088, 6176, 0, 383, 6176]\n",
            "6176\n",
            "[972, 2094, 5173, 5004, 4088, 6176, 0, 383, 6176, 6176]\n",
            "0\n",
            "[2094, 5173, 5004, 4088, 6176, 0, 383, 6176, 6176, 0]\n",
            "5632\n",
            "[5173, 5004, 4088, 6176, 0, 383, 6176, 6176, 0, 5632]\n",
            "3263\n",
            "[5004, 4088, 6176, 0, 383, 6176, 6176, 0, 5632, 3263]\n",
            "1035\n",
            "[4088, 6176, 0, 383, 6176, 6176, 0, 5632, 3263, 1035]\n",
            "1001\n",
            "[6176, 0, 383, 6176, 6176, 0, 5632, 3263, 1035, 1001]\n",
            "383\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(x[i])\n",
        "    print(y[i])\n",
        "for i in range(10):\n",
        "    print(x_num[i])\n",
        "    print(y_num[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e5821fc-f26d-43d3-ad1c-396410330255",
      "metadata": {
        "id": "6e5821fc-f26d-43d3-ad1c-396410330255"
      },
      "outputs": [],
      "source": [
        "dmodel = 512\n",
        "heads = 4\n",
        "batch_size = 32\n",
        "max_len = 10\n",
        "shape = (batch_size,max_len,dmodel)\n",
        "sentence = torch.Tensor(x_num).long()\n",
        "label = torch.Tensor(y_num).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "642e7702-4c53-4978-a74d-09f50c65802f",
      "metadata": {
        "id": "642e7702-4c53-4978-a74d-09f50c65802f"
      },
      "outputs": [],
      "source": [
        "batch = []\n",
        "for i in range(sentence.shape[0]//32):\n",
        "    if i == 0:\n",
        "        batch.append([sentence[0:32],label[0:32]])\n",
        "    else:\n",
        "        batch.append([sentence[i*32:(i+1)*32],label[i*32:(i+1)*32]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "2e3f3c3b-2c07-4e01-b76c-25153e5a7143",
      "metadata": {
        "id": "2e3f3c3b-2c07-4e01-b76c-25153e5a7143"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    '''\n",
        "    Converts the vector embedding of batch of sequence to their positional encoding vectors.\n",
        "\n",
        "    Arguments:\n",
        "            encoded_sentence : embbeding vector which is to be Positional Encoded.\n",
        "            shape : shape of embbeding vector => tuple(batch_size,max_len,dmodel)\n",
        "\n",
        "    Returns :\n",
        "            positional encoded vector\n",
        "\n",
        "    '''\n",
        "    def __init__(self,shape):\n",
        "        super().__init__()\n",
        "        self.max_len = shape[1]\n",
        "        self.dmodel = shape[2]\n",
        "        self.batch_size = shape[0]\n",
        "\n",
        "    def forward(self,x):\n",
        "        #create a position vector containing position of words\n",
        "        position = torch.arange(0, self.max_len, device=device).float().unsqueeze(1)\n",
        "\n",
        "        #applies the formula for and creates divsion term\n",
        "        div_term = torch.exp(torch.arange(0, self.dmodel, 2, device=device).float() * -(math.log(10000.0) / self.dmodel))\n",
        "\n",
        "        #creates the zeros vector of sentence shape\n",
        "        pos_enc = torch.zeros((self.batch_size, self.max_len, self.dmodel), device=device)\n",
        "\n",
        "        #applies the formula for sin(even) and cos(even)\n",
        "        pos_enc[:,:,0::2] = torch.sin(position * div_term)\n",
        "        pos_enc[:,:,1::2 ] = torch.cos(position * div_term)\n",
        "\n",
        "        #shape(batch_size,max_len,dmodel)\n",
        "        return pos_enc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "2738ce16-3467-4300-b3bb-92442eadaca1",
      "metadata": {
        "id": "2738ce16-3467-4300-b3bb-92442eadaca1"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,shape,heads):\n",
        "        super().__init__()\n",
        "\n",
        "        self.shape = shape\n",
        "        self.max_len = shape[1]\n",
        "        self.dmodel = shape[2]\n",
        "        self.batch_size = shape[0]\n",
        "        self.heads = heads\n",
        "        self.head_size = int(self.dmodel/heads)\n",
        "\n",
        "        #defines the shape of multiheaded matrix\n",
        "        self.multi_headed_shape = (self.shape[0],self.shape[1],self.heads,self.head_size)\n",
        "\n",
        "        self.k_linear = nn.Linear(self.dmodel,self.dmodel)\n",
        "        self.q_linear = nn.Linear(self.dmodel,self.dmodel)\n",
        "        self.v_linear = nn.Linear(self.dmodel,self.dmodel)\n",
        "\n",
        "    def split_heads(self,matrix,shape):\n",
        "        return matrix.view(*self.shape)\n",
        "\n",
        "\n",
        "    def attention(self,k,q,v):\n",
        "        '''\n",
        "        applies the attention formula for single heads\n",
        "\n",
        "        Arguments:\n",
        "                k : key\n",
        "                q : query\n",
        "                v : value)\n",
        "        Returns :\n",
        "                single matrix same as shape of k,q,v\n",
        "        '''\n",
        "        return torch.matmul(F.softmax((torch.matmul(q,k.transpose(-1,-2)))/(torch.sqrt(torch.tensor(dmodel/heads))),dim=-1) , v)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # shape(batch_size,max_len,dmodel)\n",
        "        K_prime = self.k_linear(x)\n",
        "        Q_prime = self.q_linear(x)\n",
        "        V_prime = self.v_linear(x)\n",
        "\n",
        "        #applies split head\n",
        "        K_prime = self.split_heads(K_prime,self.shape)\n",
        "        Q_prime = self.split_heads(Q_prime,self.shape)\n",
        "        V_prime = self.split_heads(V_prime,self.shape)\n",
        "\n",
        "        #applies attention and then concatinate\n",
        "        return self.attention(K_prime,Q_prime,V_prime).view(*self.shape)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "fd3a1554-fac1-45a2-a86a-9d817e7b0eb3",
      "metadata": {
        "id": "fd3a1554-fac1-45a2-a86a-9d817e7b0eb3"
      },
      "outputs": [],
      "source": [
        "class AddAndNorm(nn.Module):\n",
        "    def __init__(self,dmodel):\n",
        "        super().__init__()\n",
        "        self.dmodel = dmodel\n",
        "\n",
        "    def forward(self,x,residual):\n",
        "        return torch.add(residual , F.layer_norm(x,normalized_shape=(self.dmodel,)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "3abf7b27-898e-4eca-a720-1da2abea3419",
      "metadata": {
        "id": "3abf7b27-898e-4eca-a720-1da2abea3419"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(512,512,bias=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(512,512,bias=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.linear2(self.relu1(self.linear1(x)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "a997cda3-7168-4fe7-994a-48fb53bd0ed6",
      "metadata": {
        "id": "a997cda3-7168-4fe7-994a-48fb53bd0ed6"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,vocab_size,shape):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "        self.positional_encoding =  PositionalEncoding(shape)\n",
        "        self.multi_headed_attention = MultiHeadAttention(shape,4)\n",
        "        self.add_and_norm1 = AddAndNorm(512)\n",
        "        self.feed_forward = FeedForward()\n",
        "        self.add_and_norm2 = AddAndNorm(512)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.linear3 = nn.Linear(512,512)\n",
        "        self.linear4 = nn.Linear(512*10,vocab_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.token_embedding_table(x)\n",
        "        residual = self.positional_encoding(out)\n",
        "        out = self.multi_headed_attention(residual)\n",
        "        residual = self.add_and_norm1(out,residual,)\n",
        "        out = self.feed_forward(residual)\n",
        "        out = self.add_and_norm2(out,residual)\n",
        "        out = self.linear3(out)\n",
        "        out = out.view(32,-1)\n",
        "        out = self.linear4(out)\n",
        "        return self.softmax(out)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "4d2a5fe5-ee56-4594-b4e9-ef85c20bb005",
      "metadata": {
        "id": "4d2a5fe5-ee56-4594-b4e9-ef85c20bb005"
      },
      "outputs": [],
      "source": [
        "model = Encoder(vocab_size,shape)\n",
        "criterition = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "5b97bbdd-127d-495e-b32c-ab099312f78b",
      "metadata": {
        "id": "5b97bbdd-127d-495e-b32c-ab099312f78b"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.shuffle(batch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "BtN4pH0ymJ2q"
      },
      "id": "BtN4pH0ymJ2q",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2547a554-a919-416f-b263-58eca9234031",
      "metadata": {
        "id": "2547a554-a919-416f-b263-58eca9234031"
      },
      "outputs": [],
      "source": [
        "for epoch in range(10):\n",
        "    losses = []\n",
        "    for b in tqdm.tqdm(batch):\n",
        "        out = model(b[0].to(device))\n",
        "        l = F.one_hot(b[1],num_classes=vocab_size).float().to(device)\n",
        "        loss = criterition(out ,l)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss)\n",
        "    print(sum(losses) / len(losses))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}