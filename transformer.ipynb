{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunalkushwahatg/transformer_from_scratch/blob/main/transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Project is not yet completed\n"
      ],
      "metadata": {
        "id": "fnU999-N-QTT"
      },
      "id": "fnU999-N-QTT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8aca8fa-191d-4294-b199-b7fda4d55b3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8aca8fa-191d-4294-b199-b7fda4d55b3d",
        "outputId": "cc29184d-22e0-4bd4-c8a4-16a35cbb8515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import string\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import math\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Current device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d6fd62-61cb-4740-a727-d48ee65f4abd",
      "metadata": {
        "id": "62d6fd62-61cb-4740-a727-d48ee65f4abd"
      },
      "outputs": [],
      "source": [
        "file = open(\"/content/tiny-shakespeare.txt\",\"r\",encoding=\"utf-8\")\n",
        "text = file.read()\n",
        "text = text.replace(\"\\n\" , \" \").lower()\n",
        "punctuation_chars = string.punctuation\n",
        "text = ''.join(char for char in text if char not in punctuation_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9fe132d-ad12-4ddc-b57c-2e507029f5d9",
      "metadata": {
        "id": "f9fe132d-ad12-4ddc-b57c-2e507029f5d9"
      },
      "outputs": [],
      "source": [
        "tokens = text.split(\" \")\n",
        "vocab = list(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6f2ad48-ea79-4da8-aac3-fba00fc620a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6f2ad48-ea79-4da8-aac3-fba00fc620a0",
        "outputId": "02d7a8ba-e8a2-44e5-e0d1-2ffa7f5a3797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12849/12849 [01:03<00:00, 202.86it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm.tqdm(vocab):\n",
        "    if tokens.count(i) < 5:\n",
        "        tokens.remove(i)\n",
        "vocab = list(set(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "278f74d0-ba94-4893-90c7-1268dbb953d0",
      "metadata": {
        "id": "278f74d0-ba94-4893-90c7-1268dbb953d0"
      },
      "outputs": [],
      "source": [
        "vocab_to_idx = {}\n",
        "idx_to_vocab = {}\n",
        "vocab_size = len(vocab)\n",
        "for idx,v in enumerate(vocab):\n",
        "    vocab_to_idx[v] = idx\n",
        "    idx_to_vocab[idx] = v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697f756a-e3e4-49a8-8e84-7771e991898e",
      "metadata": {
        "id": "697f756a-e3e4-49a8-8e84-7771e991898e"
      },
      "outputs": [],
      "source": [
        "tokens_num = []\n",
        "for i in tokens:\n",
        "    tokens_num.append(vocab_to_idx[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3372603f-19b1-4fa5-9a96-b1b82fc47500",
      "metadata": {
        "id": "3372603f-19b1-4fa5-9a96-b1b82fc47500"
      },
      "outputs": [],
      "source": [
        "x = []\n",
        "y = []\n",
        "x_num = []\n",
        "y_num = []\n",
        "max_len = 10\n",
        "for i in range(len(tokens) - max_len - 1):\n",
        "    x.append(tokens[i:max_len+i])\n",
        "    y.append(tokens[max_len+i])\n",
        "    x_num.append(tokens_num[i:max_len+i])\n",
        "    y_num.append(tokens_num[max_len+i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa428b1-b826-42ff-96ec-3e8fe3ee9c91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfa428b1-b826-42ff-96ec-3e8fe3ee9c91",
        "outputId": "c4e13418-002a-4269-8632-33808854cd5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['first', 'citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak']\n",
            "\n",
            "['citizen', 'before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '']\n",
            "all\n",
            "['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all']\n",
            "speak\n",
            "['we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak']\n",
            "speak\n",
            "['proceed', 'any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak']\n",
            "\n",
            "['any', 'further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak', '']\n",
            "first\n",
            "['further', 'hear', 'me', 'speak', '', 'all', 'speak', 'speak', '', 'first']\n",
            "citizen\n",
            "['hear', 'me', 'speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen']\n",
            "you\n",
            "['me', 'speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen', 'you']\n",
            "are\n",
            "['speak', '', 'all', 'speak', 'speak', '', 'first', 'citizen', 'you', 'are']\n",
            "all\n",
            "[97, 1489, 817, 4312, 6031, 2129, 5301, 2934, 5607, 5243]\n",
            "0\n",
            "[1489, 817, 4312, 6031, 2129, 5301, 2934, 5607, 5243, 0]\n",
            "6577\n",
            "[817, 4312, 6031, 2129, 5301, 2934, 5607, 5243, 0, 6577]\n",
            "5243\n",
            "[4312, 6031, 2129, 5301, 2934, 5607, 5243, 0, 6577, 5243]\n",
            "5243\n",
            "[6031, 2129, 5301, 2934, 5607, 5243, 0, 6577, 5243, 5243]\n",
            "0\n",
            "[2129, 5301, 2934, 5607, 5243, 0, 6577, 5243, 5243, 0]\n",
            "97\n",
            "[5301, 2934, 5607, 5243, 0, 6577, 5243, 5243, 0, 97]\n",
            "1489\n",
            "[2934, 5607, 5243, 0, 6577, 5243, 5243, 0, 97, 1489]\n",
            "3738\n",
            "[5607, 5243, 0, 6577, 5243, 5243, 0, 97, 1489, 3738]\n",
            "4046\n",
            "[5243, 0, 6577, 5243, 5243, 0, 97, 1489, 3738, 4046]\n",
            "6577\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(x[i])\n",
        "    print(y[i])\n",
        "for i in range(10):\n",
        "    print(x_num[i])\n",
        "    print(y_num[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e5821fc-f26d-43d3-ad1c-396410330255",
      "metadata": {
        "id": "6e5821fc-f26d-43d3-ad1c-396410330255"
      },
      "outputs": [],
      "source": [
        "dmodel = 512\n",
        "heads = 4\n",
        "batch_size = 32\n",
        "max_len = 10\n",
        "shape = (batch_size,max_len,dmodel)\n",
        "sentence = torch.Tensor(x_num).long()\n",
        "label = torch.Tensor(y_num).long()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642e7702-4c53-4978-a74d-09f50c65802f",
      "metadata": {
        "id": "642e7702-4c53-4978-a74d-09f50c65802f"
      },
      "outputs": [],
      "source": [
        "batch = []\n",
        "for i in range(sentence.shape[0]//32):\n",
        "    if i == 0:\n",
        "        batch.append([sentence[0:32],label[0:32]])\n",
        "    else:\n",
        "        batch.append([sentence[i*32:(i+1)*32],label[i*32:(i+1)*32]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e3f3c3b-2c07-4e01-b76c-25153e5a7143",
      "metadata": {
        "id": "2e3f3c3b-2c07-4e01-b76c-25153e5a7143"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    '''\n",
        "    Converts the vector embedding of batch of sequence to their positional encoding vectors.\n",
        "\n",
        "    Arguments:\n",
        "            encoded_sentence : embbeding vector which is to be Positional Encoded.\n",
        "            shape : shape of embbeding vector => tuple(batch_size,max_len,dmodel)\n",
        "\n",
        "    Returns :\n",
        "            positional encoded vector\n",
        "\n",
        "    '''\n",
        "    def __init__(self,shape):\n",
        "        super().__init__()\n",
        "        self.max_len = shape[1]\n",
        "        self.dmodel = shape[2]\n",
        "        self.batch_size = shape[0]\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,x):\n",
        "        #create a position vector containing position of words\n",
        "        position = torch.arange(0, self.max_len, device=self.device).float().unsqueeze(1)\n",
        "\n",
        "        #applies the formula for and creates divsion term\n",
        "        div_term = torch.exp(torch.arange(0, self.dmodel, 2, device=device).float() * -(math.log(10000.0) / self.dmodel))\n",
        "\n",
        "        #creates the zeros vector of sentence shape\n",
        "        pos_enc = torch.zeros((self.batch_size, self.max_len, self.dmodel), device=device)\n",
        "\n",
        "        #applies the formula for sin(even) and cos(even)\n",
        "        pos_enc[:,:,0::2] = torch.sin(position * div_term)\n",
        "        pos_enc[:,:,1::2 ] = torch.cos(position * div_term)\n",
        "\n",
        "        #shape(batch_size,max_len,dmodel)\n",
        "        return pos_enc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2738ce16-3467-4300-b3bb-92442eadaca1",
      "metadata": {
        "id": "2738ce16-3467-4300-b3bb-92442eadaca1"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,shape,heads):\n",
        "        super().__init__()\n",
        "\n",
        "        self.shape = shape\n",
        "        self.max_len = shape[1]\n",
        "        self.dmodel = shape[2]\n",
        "        self.batch_size = shape[0]\n",
        "        self.heads = heads\n",
        "        self.head_size = int(self.dmodel/heads)\n",
        "\n",
        "        #defines the shape of multiheaded matrix\n",
        "        self.multi_headed_shape = (self.shape[0],self.shape[1],self.heads,self.head_size)\n",
        "\n",
        "        self.k_linear = nn.Linear(self.dmodel,self.dmodel)\n",
        "        self.q_linear = nn.Linear(self.dmodel,self.dmodel)\n",
        "        self.v_linear = nn.Linear(self.dmodel,self.dmodel)\n",
        "\n",
        "    def split_heads(self,matrix,shape):\n",
        "        return matrix.view(*self.shape)\n",
        "\n",
        "\n",
        "    def attention(self,k,q,v):\n",
        "        '''\n",
        "        applies the attention formula for single heads\n",
        "\n",
        "        Arguments:\n",
        "                k : key\n",
        "                q : query\n",
        "                v : value)\n",
        "        Returns :\n",
        "                single matrix same as shape of k,q,v\n",
        "        '''\n",
        "        return torch.matmul(F.softmax((torch.matmul(q,k.transpose(-1,-2)))/(torch.sqrt(torch.tensor(dmodel/heads))),dim=-1) , v)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # shape(batch_size,max_len,dmodel)\n",
        "        K_prime = self.k_linear(x)\n",
        "        Q_prime = self.q_linear(x)\n",
        "        V_prime = self.v_linear(x)\n",
        "\n",
        "        #applies split head\n",
        "        K_prime = self.split_heads(K_prime, self.multi_headed_shape)\n",
        "        Q_prime = self.split_heads(Q_prime, self.multi_headed_shape)\n",
        "        V_prime = self.split_heads(V_prime, self.multi_headed_shape)\n",
        "\n",
        "        #applies attention and then concatinate\n",
        "        return self.attention(K_prime,Q_prime,V_prime).view(*self.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd3a1554-fac1-45a2-a86a-9d817e7b0eb3",
      "metadata": {
        "id": "fd3a1554-fac1-45a2-a86a-9d817e7b0eb3"
      },
      "outputs": [],
      "source": [
        "class AddAndNorm(nn.Module):\n",
        "    def __init__(self,dmodel):\n",
        "        super().__init__()\n",
        "        self.dmodel = dmodel\n",
        "\n",
        "    def forward(self,x,residual):\n",
        "        return torch.add(residual , F.layer_norm(x,(self.dmodel,)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abf7b27-898e-4eca-a720-1da2abea3419",
      "metadata": {
        "id": "3abf7b27-898e-4eca-a720-1da2abea3419"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(512,512,bias=True)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(512,512,bias=True)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.linear2(self.relu1(self.linear1(x)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a997cda3-7168-4fe7-994a-48fb53bd0ed6",
      "metadata": {
        "id": "a997cda3-7168-4fe7-994a-48fb53bd0ed6"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,vocab_size,shape):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, shape[2])\n",
        "        self.positional_encoding =  PositionalEncoding(shape)\n",
        "        self.multi_headed_attention = MultiHeadAttention(shape,4)\n",
        "        self.add_and_norm1 = AddAndNorm(shape[2])\n",
        "        self.feed_forward = FeedForward()\n",
        "        self.add_and_norm2 = AddAndNorm(shape[2])\n",
        "        self.linear3 = nn.Linear(shape[2],shape[2])\n",
        "        self.linear4 = nn.Linear(shape[2]*shape[1],vocab_size)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.token_embedding_table(x)\n",
        "        residual = self.positional_encoding(out)\n",
        "        out = self.multi_headed_attention(residual)\n",
        "\n",
        "        residual = self.add_and_norm1(out,residual,)\n",
        "        out = self.feed_forward(residual)\n",
        "        out = self.add_and_norm2(out,residual)\n",
        "        out = self.linear3(out)\n",
        "        out = out.view(shape[0],-1)   # Flatten along the sequence dimension\n",
        "        out = self.linear4(out)\n",
        "        out = self.softmax(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b97bbdd-127d-495e-b32c-ab099312f78b",
      "metadata": {
        "id": "5b97bbdd-127d-495e-b32c-ab099312f78b"
      },
      "outputs": [],
      "source": [
        "model = Encoder(vocab_size,shape)\n",
        "criterition = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "import random\n",
        "random.shuffle(batch)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2547a554-a919-416f-b263-58eca9234031",
      "metadata": {
        "id": "2547a554-a919-416f-b263-58eca9234031"
      },
      "outputs": [],
      "source": [
        "for epoch in range(10):\n",
        "    losses = []\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for b in tqdm.tqdm(batch):\n",
        "        inputs, targets = b[0].to(device), b[1].to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(inputs)\n",
        "\n",
        "        # Convert targets to one-hot encoding\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=vocab_size).float()\n",
        "\n",
        "        loss = criterition(out ,targets_one_hot)\n",
        "\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        losses.append(loss)\n",
        "\n",
        "    # Calculate and print the average loss for the epoch\n",
        "    average_loss = running_loss / len(batch)\n",
        "    print(f'Epoch {epoch + 1}, Average Loss: {average_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = criterition(out ,targets_one_hot)"
      ],
      "metadata": {
        "id": "dL8uebhrk9Og"
      },
      "id": "dL8uebhrk9Og",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fml8-Hy9s_Jj",
        "outputId": "78d72df5-8ad0-4b70-b5d8-606d6844d806"
      },
      "id": "Fml8-Hy9s_Jj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8.8180, device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1sZE6vQ1tKMy"
      },
      "id": "1sZE6vQ1tKMy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}